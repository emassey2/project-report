%!TEX root = ../report.tex

\begin{document}
    \chapter{Conclusions}

    \section{Contributions}

    First and foremost, this work developed a comprehensive method for the
    comparison of various spatio-temporal world modeling methods. Although as
    some previous work in this area
    already exists, that work was limited both in its ability to be applied to various
    methods and the depth at which any two methods could be compared. The
    new techniques for comparison established in the Criteria for Comparison
    section built on the current methods to offer increased breadth and depth.
    Furthermore, the ROPOD case study section shows in detail how these new testing criteria
    can be used with respect to an actual project. This is an extremely important
    contribution as nearly all previous work merely used criteria to look reflexively
    at the quality of a new approach and not which method may be
    best suited for a given problem. \\

    Building on the qualitative analysis work already presented in this
    paper, the experimental section provided guidelines for how one would select
    a set of experiments to test and refine previously obtained results.
    These experiments highlight unique aspects of the techniques presented that
    were not necessarily highlighted in their original papers.
    Additionally, this section provides a roadmap for what types of experiments
    should be done, what results to look for, and how to evaluate those results.
    Beyond a roadmap, a novel approach for applying binary classification to
    non-binary data was presented and demonstrated. Lastly, some new metrics
    were proposed to evaluate path planning. \\

    Finally, a common thread for both the qualitative and experimental
    sections was the emphasis placed on experiments being done with respect to a
    real-world project. Although, in the past some work has been done with real
    world projects, comparative techniques primarily focused on
    the performance of the existing specific algorithm under test. That is to say, previous work has
    focused solely on how ``correct'' a spatio-temporal modeling technique was
    for an individual object. This work focuses on additional information like
    computational intensity, and performance when working with the
    resulting predictions. \\

    \subsection{ Recommendations for ROPOD }

    After paring down the initial list of methods for spatio-temporal
    world modeling, designing and running the experiments, and analyzing the
    results, it is time to make the final recommendations. An important note
    is that despite being included in the experiments, the Gaussian model will
    not be considered in the recommendations. This is because its inclusion was
    for comparison sake and not as a serious contender. Additionally, it
    also had consistently the worst accuracy. With that aside, the methods
    under consideration are dynamic multi-maps, FreMEn, and Hypertime.
    Dynamic multi-maps are a tempting option given their low computational
    usage and occasional moments of high performance and accuracy. Despite these upsides,
    the dynamic multi-maps are not recommended due to the high level of maintenance
    and tuning required to achieve high accuracy predictions. That leaves the
    final two methods, FreMEn and Hypertime. Both of these methods have fairly
    similar performance when making binary predictions with Hypertime having a
    bit of an edge in accuracy, but FreMEn edging Hypertime out in computational
    resource usage. However, this is not the case when working with non-binary
    data. In this case, Hypertime had a noticeable lead in prediction accuracy.
    This does not come with an additional penalty with respect to computational
    usage though. \\

    In order to best weigh this trade off it is necessary to review the ways
    that ROPOD will use spatio-temporal world modeling. Predictions will
    be used for determining optimal path planning by modifying a preexisting
    world model. Since both FreMEn and Hypertime use offline learning, the models
    can be trained overnight during a period of low usage. A central server
    will be used for data storage and training. This is advantageous because
    it allows computational power and resources be concentrated instead of each
    robot being individually responsible for processing. Centralization
    allows an older model to be stored on the central server and used
    while a newer one is trained. Because an old model can be used while a new
    one is trained, training time is less of a concern.
    Given it's high accuracy, and the central servers ability to mitigate some
    of the heavier resource usage, it is recommended that Hypertime be chosen
    for use with ROPOD. \\

    Integration can be achieved by establishing a database on the central server
    where observations made by robots in the field can be stored along
    with a timestamp. At times of low ROPOD usage, most likely overnight, new
    models can be trained for usage during the next day. During this time,
    observations will be retrieved from the database, sorted, and used to make
    models for each of the desired objects or behaviors. That is to say, for
    doors, graph edges, etc. Once the new models are complete, whenever a query is
    made for a given time they will be asked to produce a prediction.
    Those predictions will then be used to modify the existing world model at
    which point path planning can take place. If, as the project scales, it is
    determined that Hypertime is too much of a computational drain FreMEn
    can be introduced for use with binary data to lighten the load. \\


    \section{ Future work }

    Although this work has made helpful contributions to the field, it is
    certain that further work remains. ROPOD can be used as an example
    to base future studies. This is particularly true because ROPOD, unlike previous work, is a multi-robot
    system. This means that while running tests with respect to a single robot
    is valid and fully accurate, the addition of multiple robots creates
    additional opportunities and complexities. Having multiple robots moving about
    the environment at different times allows for gathering much
    more data. This in turn decreases the sparsity of data
    available for testing and developing models. Furthermore, this is likely to increase model accuracy as evident in the
    elevator experiments, but may also cause issues when trying to mitigate
    or merge multiple samples of the same object at the same time. Moreover,
    the very presence of multiple robots may themselves introduce spatio-temporal
    complexities. Having multiple robots moving about a shared
    space, especially during peak traffic, could create additional obstacles
    in the form of congestion that would need to be planned around
    and accounted for in advance. \\

    Another area of future work is the collection
    of additional real-world data. This data is often more noisy, irregular,
    and generally unpredictable when compared to even the best simulated data.
    Ideally this new data new data will be collected and compiled into a
    new dataset for use in other experiments. Early steps have been been taken as exemplified in the
    ``Brayford'' dataset \cite{Krajnik2014}. This dataset, however, contains
    only 3D data for a single room. The observation was done using a static device and
    thus observations are at regular intervals and contain minimal noise.
    Furthermore, because this is was only one device the complexities of a
    multi-robot system are also overlooked. The work done in this paper is an
    excellent step in the right direction, but the field of spatio-temporal
    world modeling remains open with many rich and intricate problems left for
    exploration. \\

\end{document}
